{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0ca814-f2c5-491c-961b-268ccb89e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stoi : {'\\n': 0, ' ': 1, ',': 2, '-': 3, '.': 4, ':': 5, '?': 6, 'a': 7, 'b': 8, 'c': 9, 'd': 10, 'e': 11, 'f': 12, 'g': 13, 'h': 14, 'i': 15, 'j': 16, 'l': 17, 'm': 18, 'n': 19, 'o': 20, 'p': 21, 'q': 22, 'r': 23, 's': 24, 't': 25, 'u': 26, 'v': 27, 'x': 28, 'y': 29, 'Ã ': 30, 'Ã¨': 31, 'Ã©': 32, 'Ãª': 33, 'Ã®': 34, 'â€™': 35}\n",
      "itos : {0: '\\n', 1: ' ', 2: ',', 3: '-', 4: '.', 5: ':', 6: '?', 7: 'a', 8: 'b', 9: 'c', 10: 'd', 11: 'e', 12: 'f', 13: 'g', 14: 'h', 15: 'i', 16: 'j', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'x', 29: 'y', 30: 'Ã ', 31: 'Ã¨', 32: 'Ã©', 33: 'Ãª', 34: 'Ã®', 35: 'â€™'}\n",
      "tensor([25, 15, 25, 23, 11,  1,  5,  1, 17, 11,  1,  9, 14,  7, 25,  1,  9, 26,\n",
      "        23, 15, 11, 26, 28,  0,  0, 26, 19,  1, 16, 20, 26, 23,  2,  1, 10,  7,\n",
      "        19, 24,  1, 26, 19,  1, 21, 11, 25, 15, 25,  1, 27, 15, 17, 17,  7, 13,\n",
      "        11,  1, 11, 19, 25, 20, 26, 23, 32,  1, 10, 11,  1,  9, 20, 17, 17, 15,\n",
      "        19, 11, 24,  2,  1, 27, 15, 27,  7, 15, 25,  1, 26, 19,  1,  9, 14,  7,\n",
      "        25,  1, 19, 20, 18, 18, 32,  1, 18, 15, 18, 20,  4,  1, 18, 15, 18, 20,\n",
      "         1, 19, 35, 32, 25,  7, 15, 25,  1, 21,  7, 24,  1, 26, 19,  1,  9, 14,\n",
      "         7, 25,  1,  9, 20, 18, 18, 11,  1, 17, 11, 24,  1,  7, 26, 25, 23, 11,\n",
      "        24,  1,  5,  1, 15, 17,  1,  7, 10, 20, 23,  7, 15, 25,  1, 11, 28, 21,\n",
      "        17, 20, 23, 11, 23,  4,  1,  9, 14,  7, 22, 26, 11,  1, 18,  7, 25, 15,\n",
      "        19,  2,  1, 15, 17,  1, 22, 26, 15, 25, 25,  7, 15, 25,  1, 24,  7,  1,\n",
      "        18,  7, 15, 24, 20, 19,  1, 11, 25,  1, 21,  7, 23, 25,  7, 15, 25,  1,\n",
      "        30,  1, 17, 35,  7, 27, 11, 19, 25, 26, 23, 11,  2,  1, 23, 11, 19, 15,\n",
      "        12, 17,  7, 19, 25,  1, 17, 11, 24,  1, 12, 17, 11, 26, 23, 24,  2,  1,\n",
      "        20,  8, 24, 11, 23, 27,  7, 19, 25,  1, 17, 11, 24,  1, 20, 15, 24, 11,\n",
      "         7, 26, 28,  2,  1, 11, 25,  1, 21,  7, 23, 12, 20, 15, 24,  1, 18, 33,\n",
      "        18, 11,  1, 13, 23, 15, 18, 21,  7, 19, 25,  1, 24, 26, 23,  1, 17, 11,\n",
      "        24,  1, 25, 20, 15, 25, 24,  4,  0,  0, 26, 19,  1, 18,  7, 25, 15, 19,\n",
      "         2,  1, 15, 17,  1, 25, 23, 20, 26, 27,  7,  1, 26, 19, 11,  1,  8, 20,\n",
      "        34, 25, 11,  1, 18, 29, 24, 25, 32, 23, 15, 11, 26, 24, 11,  1, 10, 11,\n",
      "        23, 23, 15, 31, 23, 11,  1, 17,  7,  1,  8, 20, 26, 17,  7, 19, 13, 11,\n",
      "        23, 15, 11,  4,  1, 11, 17, 17, 11,  1, 12,  7, 15, 24,  7, 15, 25,  1,\n",
      "        26, 19,  1, 17, 32, 13, 11, 23,  1,  8, 23, 26, 15, 25,  2,  1,  9, 20,\n",
      "        18, 18, 11,  1, 24, 15,  1, 22, 26, 11, 17, 22, 26, 11,  1,  9, 14, 20,\n",
      "        24, 11,  1,  8, 20, 26, 13, 11,  7, 15, 25,  1, 30,  1, 17, 35, 15, 19,\n",
      "        25, 32, 23, 15, 11, 26, 23,  4,  1, 18, 15, 18, 20,  1, 24, 35,  7, 21,\n",
      "        21, 23, 20,  9, 14,  7,  1, 21, 23, 26, 10, 11, 18, 18, 11, 19, 25,  2,\n",
      "         1, 17, 11, 24,  1, 18, 20, 26, 24, 25,  7,  9, 14, 11, 24,  1, 12, 23,\n",
      "        32, 18, 15, 24, 24,  7, 19, 25, 11, 24,  4,  1, 22, 26, 11,  1, 21, 20,\n",
      "        26, 27,  7, 15, 25,  3, 11, 17, 17, 11,  1,  8, 15, 11, 19,  1,  9, 20,\n",
      "        19, 25, 11, 19, 15, 23,  1,  6])\n",
      "Texte encodÃ©. Taille vocabulaire : 36\n",
      "x shape : torch.Size([4, 64])\n",
      "y shape : torch.Size([4, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. Charger le fichier texte\n",
    "with open('exemple.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "text = text.strip().lower()\n",
    "\n",
    "# 2. Vocabulaire\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "print(\"stoi :\",stoi)\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "print(\"itos :\",itos)\n",
    "\n",
    "# 3. Encodage\n",
    "data = torch.tensor([stoi[c] for c in text], dtype=torch.long)\n",
    "print(data)\n",
    "block_size = 64\n",
    "\n",
    "# 4. Dataset personnalisÃ©\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx : idx + self.block_size]\n",
    "        y = self.data[idx + 1 : idx + 1 + self.block_size]\n",
    "        return x, y\n",
    "\n",
    "# 5. CrÃ©er le DataLoader\n",
    "batch_size = 4\n",
    "dataset = CharDataset(data, block_size)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 6. Exemple dâ€™utilisation\n",
    "x, y = next(iter(dataloader))\n",
    "print(\"Texte encodÃ©. Taille vocabulaire :\", vocab_size)\n",
    "print(\"x shape :\", x.shape)  # [batch_size, block_size]\n",
    "print(\"y shape :\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd02c635-c812-4895-87d7-76114e157f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‰tape 0 â€“ Perte : 3.7334\n",
      "Ã‰tape 100 â€“ Perte : 2.5172\n",
      "Ã‰tape 200 â€“ Perte : 2.2097\n",
      "Ã‰tape 300 â€“ Perte : 2.1297\n",
      "Ã‰tape 400 â€“ Perte : 2.0330\n",
      "âœ… EntraÃ®nement terminÃ©.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# DÃ©finition dâ€™un mini-modÃ¨le GPT\n",
    "class TinyGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embed=64):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        x = self.embed(idx)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits\n",
    "\n",
    "# Initialisation\n",
    "model = TinyGPT(vocab_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# PrÃ©parer un itÃ©rateur persistant sur le dataloader\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "# EntraÃ®nement simple\n",
    "for step in range(500):\n",
    "    try:\n",
    "        x, y = next(data_iter)\n",
    "    except StopIteration:\n",
    "        data_iter = iter(dataloader)\n",
    "        x, y = next(data_iter)\n",
    "\n",
    "    logits = model(x)\n",
    "    B, T, C = logits.shape\n",
    "    loss = loss_fn(logits.view(B * T, C), y.view(B * T))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Ã‰tape {step} â€“ Perte : {loss.item():.4f}\")\n",
    "\n",
    "print(\"âœ… EntraÃ®nement terminÃ©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cbd97e2-2c81-4b82-9706-cd85218126bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, prompt, max_new_tokens=100, temperature=1.0, top_k=None, top_p=None):\n",
    "    model.eval()\n",
    "    idx = torch.tensor([stoi[c] for c in prompt], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -block_size:]\n",
    "        logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :] / temperature  # tempÃ©rature\n",
    "\n",
    "        # Appliquer top-k\n",
    "        if top_k is not None:\n",
    "            topk_vals, topk_idx = torch.topk(logits, top_k)\n",
    "            logits_filtered = torch.full_like(logits, float('-inf'))\n",
    "            logits_filtered.scatter_(1, topk_idx, topk_vals)\n",
    "            logits = logits_filtered\n",
    "\n",
    "        # Appliquer top-p (nucleus)\n",
    "        if top_p is not None:\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "            # Masque les tokens dÃ©passant top_p\n",
    "            sorted_mask = cumulative_probs > top_p\n",
    "            sorted_mask[..., 1:] = sorted_mask[..., :-1].clone()\n",
    "            sorted_mask[..., 0] = 0  # Garder au moins 1\n",
    "\n",
    "            logits[0, sorted_indices[0][sorted_mask[0]]] = float('-inf')\n",
    "\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    out = ''.join([itos[i.item()] for i in idx[0]])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807a302a-320a-4643-bce6-b5bc7ca2c2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”® Texte gÃ©nÃ©rÃ© :\n",
      "\n",
      "un matin, lâ€™ait le pa lâ€™ailet llle mererun fletaqun, choiese pes dare dese Ã  ur. mmat qugerier. pait mis lesat l bo uvan chailant de mauge llqun mouromer. mitÃ©t mit, Ã  ese lant les, borounta omomouge boses, ll\n"
     ]
    }
   ],
   "source": [
    "prompt = \"un matin,\"\n",
    "generated_text = generate(model, prompt, max_new_tokens=200, temperature=0.8, top_k=20, top_p=0.9)\n",
    "\n",
    "print(\"ðŸ”® Texte gÃ©nÃ©rÃ© :\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27673746-96f8-401e-9d97-523abbc1bf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
